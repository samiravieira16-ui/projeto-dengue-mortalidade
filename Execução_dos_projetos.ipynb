{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samiravieira16-ui/projeto-dengue-mortalidade/blob/main/Execu%C3%A7%C3%A3o_dos_projetos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Leitura dos dados Convertidos**\n",
        "## Instala√ß√µes e autoriza√ß√µes necessarias para o acesso do local de consulta."
      ],
      "metadata": {
        "id": "j84rUpD-d6Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Montar o Google Drive (autorize quando pedir) essa celula √© necessaria somente no Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 0) Caminho para a pasta onde est√£o os .parquet ap√≥s adicionar atalho √† \"Meu Drive\".\n",
        "DATA_DIR = \"/content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet\"   # <- altere conforme seu MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8BiX1CQCxyH4",
        "outputId": "3f10f763-9671-443c-a457-902edc935a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cabe√ßalho do Dataset**\n",
        "---\n",
        "Verificando se as colunas s√£o totalmente iguais"
      ],
      "metadata": {
        "id": "03LWwE3N1XsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# DATA_DIR = \"/data/Parquet\"   # <- altere conforme o caminho dos arquivos parquet\n",
        "DATA_DIR = \"/content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet\"\n",
        "specific_parquet_file = f\"{DATA_DIR}/DENGBR25.parquet\"\n",
        "\n",
        "# Leitura do arquivo .parquet\n",
        "df_specific = pd.read_parquet(specific_parquet_file)\n",
        "\n",
        "print(f\"Primeiras 2 linhas do arquivo {specific_parquet_file}:\")\n",
        "print(df_specific.head(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzW3_rZp1cJK",
        "outputId": "c0e72141-cb7a-43ee-952e-7f4ad82362ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeiras 2 linhas do arquivo /content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet/DENGBR25.parquet:\n",
            "  TP_NOT ID_AGRAVO  DT_NOTIFIC SEM_NOT NU_ANO SG_UF_NOT ID_MUNICIP ID_REGIONA ID_UNIDADE  DT_SIN_PRI SEM_PRI ANO_NASC NU_IDADE_N CS_SEXO CS_GESTANT CS_RACA CS_ESCOL_N SG_UF ID_MN_RESI ID_RG_RESI ID_PAIS DT_INVEST ID_OCUPA_N FEBRE MIALGIA CEFALEIA EXANTEMA VOMITO NAUSEA DOR_COSTAS CONJUNTVIT ARTRITE ARTRALGIA PETEQUIA_N LEUCOPENIA  LACO DOR_RETRO DIABETES HEMATOLOG HEPATOPAT RENAL HIPERTENSA ACIDO_PEPT AUTO_IMUNE DT_CHIK_S1 DT_CHIK_S2 DT_PRNT RES_CHIKS1 RES_CHIKS2 RESUL_PRNT DT_SORO RESUL_SORO DT_NS1 RESUL_NS1 DT_VIRAL RESUL_VI_N DT_PCR RESUL_PCR_ SOROTIPO HISTOPA_N IMUNOH_N HOSPITALIZ DT_INTERNA    UF MUNICIPIO TPAUTOCTO COUFINF COPAISINF COMUNINF CLASSI_FIN CRITERIO DOENCA_TRA CLINC_CHIK EVOLUCAO DT_OBITO DT_ENCERRA ALRM_HIPOT ALRM_PLAQ ALRM_VOM ALRM_SANG ALRM_HEMAT ALRM_ABDOM ALRM_LETAR ALRM_HEPAT ALRM_LIQ DT_ALRM GRAV_PULSO GRAV_CONV GRAV_ENCH GRAV_INSUF GRAV_TAQUI GRAV_EXTRE GRAV_HIPOT GRAV_HEMAT GRAV_MELEN GRAV_METRO GRAV_SANG GRAV_AST GRAV_MIOC GRAV_CONSC GRAV_ORGAO DT_GRAV  \\\n",
            "0      2       A90  2025-11-26  202548   2025        15     150555       1495    2615975  2025-11-18  202547     1938       4087       M          6       4          3    15     150555       1495       1      None       None  None    None     None     None   None   None       None       None    None      None       None       None  None      None     None      None      None  None       None       None       None       None       None    None       None       None       None    None       None   None      None     None       None   None       None     None      None     None       None       None  None      None      None    None      None     None       None     None       None       None     None     None       None       None      None     None      None       None       None       None       None     None    None       None      None      None       None       None       None       None       None       None       None      None     None      None       None       None    None   \n",
            "\n",
            "  MANI_HEMOR EPISTAXE GENGIVO METRO PETEQUIAS HEMATURA SANGRAM LACO_N PLASMATICO EVIDENCIA PLAQ_MENOR CON_FHD COMPLICA TP_SISTEMA NDUPLIC_N   DT_DIGITA CS_FLXRET FLXRECEBI MIGRADO_W  \n",
            "0       None     None    None  None      None     None    None   None       None      None       None    None     None          2      None  2025-11-28         0      None      None  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analise dos ultimos 5 anos de dados\n",
        "\n",
        "Os dados apresentam inconsist√™ncias entre as colunas, existe nomes diferentes de colunas para um mesmo significado.\n",
        "Dessa forma, foi feito a paridade entre as colunas e estabelecendo os nomes individualmente das colunas para o seguintes anos e corrigindo:\n",
        "\n",
        "### DENGBR21 √© igual ao DENGBR22\n",
        "---\n",
        "### DENGBR23 √© igual ao DENGBR24\n",
        "---\n",
        "### DENGBR25 √© diferente dos demais\n",
        "---"
      ],
      "metadata": {
        "id": "jsEwiI6X5vU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc # Garbage Collector\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CONFIGURA√á√ÉO E LISTA MESTRA DE COLUNAS\n",
        "# ==============================================================================\n",
        "# DATA_DIR = \"/data/Parquet\"   # <- altere conforme o caminho dos arquivos parquet\n",
        "DATA_DIR = \"/content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet\"\n",
        "OUTPUT_DIR = os.path.join(DATA_DIR, \"Dataset_Limpo_Final\")\n",
        "\n",
        "# Cria a pasta de sa√≠da se n√£o existir\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Sua lista de colunas OFICIAL\n",
        "COLUNAS_OFICIAIS = [\n",
        "    'TP_NOT', 'ID_AGRAVO', 'DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'SG_UF_NOT',\n",
        "    'ID_MUNICIP', 'ID_REGIONA', 'ID_UNIDADE', 'UF', 'MUNICIPIO', 'ID_MN_RESI',\n",
        "    'ID_RG_RESI', 'SG_UF', 'ID_PAIS', 'DT_SIN_PRI', 'SEM_PRI', 'ANO_NASC',\n",
        "    'NU_IDADE_N', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N', 'ID_OCUPA_N',\n",
        "    'FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA', 'VOMITO', 'NAUSEA', 'DOR_COSTAS',\n",
        "    'CONJUNTVIT', 'ARTRITE', 'ARTRALGIA', 'PETEQUIA_N', 'LEUCOPENIA', 'LACO',\n",
        "    'DOR_RETRO', 'DIABETES', 'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA',\n",
        "    'ACIDO_PEPT', 'AUTO_IMUNE', 'DT_INVEST', 'DT_CHIK_S1', 'DT_CHIK_S2', 'DT_PRNT',\n",
        "    'RES_CHIKS1', 'RES_CHIKS2', 'RESUL_PRNT', 'DT_SORO', 'RESUL_SORO', 'DT_NS1',\n",
        "    'RESUL_NS1', 'DT_VIRAL', 'RESUL_VI_N', 'DT_PCR', 'RESUL_PCR_', 'SOROTIPO',\n",
        "    'HISTOPA_N', 'IMUNOH_N', 'CLASSI_FIN', 'CRITERIO', 'TPAUTOCTO', 'COUFINF',\n",
        "    'COPAISINF', 'COMUNINF', 'DOENCA_TRA', 'CLINC_CHIK', 'EVOLUCAO', 'DT_OBITO',\n",
        "    'DT_ENCERRA', 'HOSPITALIZ', 'DT_INTERNA', 'ALRM_HIPOT', 'ALRM_PLAQ', 'ALRM_VOM',\n",
        "    'ALRM_SANG', 'ALRM_HEMAT', 'ALRM_ABDOM', 'ALRM_LETAR', 'ALRM_HEPAT', 'ALRM_LIQ',\n",
        "    'DT_ALRM', 'GRAV_PULSO', 'GRAV_CONV', 'GRAV_ENCH', 'GRAV_INSUF', 'GRAV_TAQUI',\n",
        "    'GRAV_EXTRE', 'GRAV_HIPOT', 'GRAV_HEMAT', 'GRAV_MELEN', 'GRAV_METRO',\n",
        "    'GRAV_SANG', 'GRAV_AST', 'GRAV_MIOC', 'GRAV_CONSC', 'GRAV_ORGAO', 'DT_GRAV',\n",
        "    'MANI_HEMOR', 'EPISTAXE', 'GENGIVO', 'METRO', 'PETEQUIAS', 'HEMATURA', 'SANGRAM',\n",
        "    'LACO_N', 'PLASMATICO', 'EVIDENCIA', 'PLAQ_MENOR', 'CON_FHD', 'COMPLICA',\n",
        "    'TP_SISTEMA', 'NDUPLIC_N', 'DT_DIGITA', 'CS_FLXRET', 'FLXRECEBI', 'MIGRADO_W'\n",
        "]\n",
        "\n",
        "# Colunas que podem ser transformadas em CATEGORIA para economizar RAM\n",
        "COLS_CATEGORIA = [\n",
        "    'TP_NOT', 'SG_UF_NOT', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N',\n",
        "    'FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA', 'VOMITO', 'NAUSEA', 'DOR_COSTAS',\n",
        "    'CONJUNTVIT', 'ARTRITE', 'ARTRALGIA', 'PETEQUIA_N', 'LEUCOPENIA', 'LACO',\n",
        "    'DIABETES', 'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA', 'AUTO_IMUNE',\n",
        "    'CLASSI_FIN', 'EVOLUCAO', 'CRITERIO', 'HOSPITALIZ'\n",
        "]\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FUN√á√ÉO DE OTIMIZA√á√ÉO\n",
        "# ==============================================================================\n",
        "def processar_e_salvar(ano, arquivo_entrada, pasta_saida):\n",
        "    print(f\"--> Processando Ano 20{ano}...\", end=\" \")\n",
        "\n",
        "    try:\n",
        "        # A. Ler arquivo\n",
        "        df = pd.read_parquet(arquivo_entrada)\n",
        "\n",
        "        # B. Padronizar Colunas (Reindex)\n",
        "        # Cria colunas faltantes com NaN e descarta as in√∫teis\n",
        "        df = df.reindex(columns=COLUNAS_OFICIAIS)\n",
        "\n",
        "        # C. Adicionar Ano de Origem\n",
        "        df['ANO_ORIGEM'] = int(\"20\" + ano)\n",
        "\n",
        "        # D. Otimiza√ß√£o de Mem√≥ria (Downcasting)\n",
        "        # 1. Converter Float64 -> Float32\n",
        "        cols_float = df.select_dtypes(include=['float64']).columns\n",
        "        df[cols_float] = df[cols_float].astype('float32')\n",
        "\n",
        "        # 2. Converter Object -> Category\n",
        "        for col in COLS_CATEGORIA:\n",
        "            if col in df.columns:\n",
        "                # Converte apenas se n√£o for tudo nulo\n",
        "                if df[col].notna().any():\n",
        "                    df[col] = df[col].astype('category')\n",
        "\n",
        "        # E. Salvar Imediatamente (Partitioning)\n",
        "        # Salvamos como uma \"fatia\" do dataset final\n",
        "        caminho_saida = os.path.join(pasta_saida, f\"part_dengue_20{ano}.parquet\")\n",
        "        df.to_parquet(caminho_saida, index=False)\n",
        "\n",
        "        print(f\"SALVO! (Mem√≥ria liberada)\")\n",
        "\n",
        "        # F. Limpeza de Mem√≥ria Expl√≠cita\n",
        "        del df\n",
        "        gc.collect() # Chama o GC\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERRO: {e}\")\n",
        "        return False\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. EXECU√á√ÉO DO FLUXO\n",
        "# ==============================================================================\n",
        "ANOS = ['21', '22', '23', '24', '25']\n",
        "\n",
        "print(f\"Iniciando pipeline de unifica√ß√£o com economia de mem√≥ria.\")\n",
        "print(f\"Os arquivos processados ser√£o salvos em: {OUTPUT_DIR}\\n\")\n",
        "\n",
        "for ano in ANOS:\n",
        "    arquivo = f\"{DATA_DIR}/DENGBR{ano}.parquet\"\n",
        "    if os.path.exists(arquivo):\n",
        "        processar_e_salvar(ano, arquivo, OUTPUT_DIR)\n",
        "    else:\n",
        "        print(f\"AVISO: Arquivo 20{ano} n√£o encontrado.\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"PROCESSO CONCLU√çDO!\\n\")\n",
        "print(\"Para ler o dataset completo sem estourar a mem√≥ria, use:\")\n",
        "print(f\"df_completo = pd.read_parquet('{OUTPUT_DIR}')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YEoB8SRrfk86",
        "outputId": "6c8fcbb5-2d54-4162-f9c2-3f0c4153757e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando pipeline de unifica√ß√£o com economia de mem√≥ria.\n",
            "Os arquivos processados ser√£o salvos em: /content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet/Dataset_Unificado_Otimizado\n",
            "\n",
            "--> Processando Ano 2021... SALVO! (Mem√≥ria liberada)\n",
            "--> Processando Ano 2022... SALVO! (Mem√≥ria liberada)\n",
            "--> Processando Ano 2023... SALVO! (Mem√≥ria liberada)\n",
            "--> Processando Ano 2024... "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabalhando com os Dataset\n",
        "---\n",
        "## Reestruturando de acordo com as novas regras das colunas.\n",
        "---"
      ],
      "metadata": {
        "id": "7c_NQ6GMuLYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CONFIGURA√á√ÉO DE CAMINHOS\n",
        "# ==============================================================================\n",
        "DATA_DIR = \"/content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet\"\n",
        "INPUT_DIR = os.path.join(DATA_DIR, \"Dataset_Limpo_Final\")\n",
        "OUTPUT_DIR = os.path.join(DATA_DIR, \"Dataset_Pronto_Para_Uso\") # Pasta nova\n",
        "\n",
        "# Cria a pasta de sa√≠da\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Lendo de: {INPUT_DIR}\")\n",
        "print(f\"Escrevendo em: {OUTPUT_DIR}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DICION√ÅRIO DE RENOMEA√á√ÉO (Obrigat√≥rio)\n",
        "# ==============================================================================\n",
        "dict_renomear = {\n",
        "    # Identifica√ß√£o\n",
        "    'TP_NOT': 'Tipo_Notificacao', 'ID_AGRAVO': 'Codigo_Doenca', 'DT_NOTIFIC': 'Data_Notificacao',\n",
        "    'NU_ANO': 'Ano_Notificacao', 'SG_UF_NOT': 'UF_Notificacao', 'UF': 'UF_Residencia',\n",
        "    'MUNICIPIO': 'Municipio_Residencia', 'ID_MN_RESI': 'Cod_Municipio_Residencia', 'ID_PAIS': 'Pais_Residencia',\n",
        "    # Paciente\n",
        "    'DT_SIN_PRI': 'Data_Inicio_Sintomas', 'NU_IDADE_N': 'Idade_Codificada',\n",
        "    'CS_SEXO': 'Sexo', 'CS_RACA': 'Raca_Cor', 'CS_ESCOL_N': 'Escolaridade',\n",
        "    'CS_GESTANT': 'Gestante', 'ID_OCUPA_N': 'Ocupacao',\n",
        "    # Sintomas\n",
        "    'FEBRE': 'Sintoma_Febre', 'MIALGIA': 'Sintoma_DorCorpo', 'CEFALEIA': 'Sintoma_DorCabeca',\n",
        "    'EXANTEMA': 'Sintoma_Manchas', 'VOMITO': 'Sintoma_Vomito', 'NAUSEA': 'Sintoma_Nausea',\n",
        "    'DOR_COSTAS': 'Sintoma_DorCostas', 'CONJUNTVIT': 'Sintoma_Conjuntivite',\n",
        "    'ARTRITE': 'Sintoma_Artrite', 'ARTRALGIA': 'Sintoma_DorArticulacao',\n",
        "    'PETEQUIA_N': 'Sintoma_Petequias', 'LEUCOPENIA': 'Sintoma_Leucopenia',\n",
        "    'LACO': 'Sintoma_ProvaLaco', 'DOR_RETRO': 'Sintoma_DorRetroorbital',\n",
        "    # Comorbidades\n",
        "    'DIABETES': 'Comorb_Diabetes', 'HEMATOLOG': 'Comorb_Hematolog', 'HEPATOPAT': 'Comorb_Hepatopat',\n",
        "    'RENAL': 'Comorb_Renal', 'HIPERTENSA': 'Comorb_Hipertensao',\n",
        "    'ACIDO_PEPT': 'Comorb_AcidoPeptica', 'AUTO_IMUNE': 'Comorb_AutoImune',\n",
        "    # Alarme e Gravidade\n",
        "    'ALRM_HIPOT': 'Alarme_Hipotensao', 'ALRM_PLAQ': 'Alarme_QuedaPlaquetas',\n",
        "    'ALRM_VOM': 'Alarme_VomitoPersistente', 'ALRM_SANG': 'Alarme_SangramentoMucosa',\n",
        "    'ALRM_HEMAT': 'Alarme_AumentoHematocrito', 'ALRM_ABDOM': 'Alarme_DorAbdominal',\n",
        "    'ALRM_LETAR': 'Alarme_Letargia', 'GRAV_PULSO': 'Gravidade_PulsoDebil',\n",
        "    'GRAV_CONV': 'Gravidade_PA_Convergente', 'GRAV_ENCH': 'Gravidade_EnchimentoLento',\n",
        "    'GRAV_INSUF': 'Gravidade_InsufRespiratoria', 'GRAV_TAQUI': 'Gravidade_Taquicardia',\n",
        "    'GRAV_EXTRE': 'Gravidade_ExtremidadesFrias',\n",
        "    # Desfecho\n",
        "    'CLASSI_FIN': 'Classificacao_Final', 'CRITERIO': 'Criterio_Confirmacao',\n",
        "    'EVOLUCAO': 'Desfecho_Caso', 'DT_OBITO': 'Data_Obito',\n",
        "    'DT_ENCERRA': 'Data_Encerramento', 'HOSPITALIZ': 'Houve_Hospitalizacao',\n",
        "    'DT_INTERNA': 'Data_Internacao'\n",
        "}\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. FUN√á√ÉO DE PROCESSAMENTO (1 Arquivo por vez)\n",
        "# ==============================================================================\n",
        "def processar_lote(arquivo_entrada, arquivo_saida):\n",
        "    print(f\"--> Processando: {os.path.basename(arquivo_entrada)}...\", end=\" \")\n",
        "\n",
        "    try:\n",
        "        # A. Carrega apenas este arquivo\n",
        "        df = pd.read_parquet(arquivo_entrada)\n",
        "\n",
        "        # B. Renomeia IMEDIATAMENTE (Resolve o erro KeyError)\n",
        "        df = df.rename(columns=dict_renomear)\n",
        "\n",
        "        # C. Dados regras do PDF (C√°lculos)\n",
        "        # Datas\n",
        "        cols_data = ['Data_Notificacao', 'Data_Inicio_Sintomas', 'Data_Obito', 'Data_Encerramento']\n",
        "        for col in cols_data:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "        # Idade Real\n",
        "        if 'Idade_Codificada' in df.columns:\n",
        "            df['Idade_Codificada'] = pd.to_numeric(df['Idade_Codificada'], errors='coerce')\n",
        "            condicoes = [df['Idade_Codificada'].isna(), df['Idade_Codificada'] >= 4000]\n",
        "            escolhas = [np.nan, df['Idade_Codificada'] - 4000]\n",
        "            df['Idade_Em_Anos'] = np.select(condicoes, escolhas, default=0)\n",
        "\n",
        "        # Classifica√ß√£o Final\n",
        "        if 'Classificacao_Final' in df.columns:\n",
        "            df['Classificacao_Final'] = pd.to_numeric(df['Classificacao_Final'], errors='coerce')\n",
        "            mapa = {10: 'Dengue', 11: 'Dengue com Sinais de Alarme', 12: 'Dengue Grave', 5: 'Descartado'}\n",
        "            df['Descricao_Classificacao'] = df['Classificacao_Final'].map(mapa)\n",
        "\n",
        "        # D. Otimiza√ß√£o de Mem√≥ria\n",
        "        cols_cat = ['Sexo', 'Raca_Cor', 'UF_Notificacao', 'Descricao_Classificacao', 'Desfecho_Caso']\n",
        "        for col in cols_cat:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].astype('category')\n",
        "\n",
        "        # E. Salva o resultado limpo\n",
        "        df.to_parquet(arquivo_saida, index=False)\n",
        "        print(\"OK (Salvo).\")\n",
        "\n",
        "        # F. Limpeza de RAM\n",
        "        del df\n",
        "        gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"FALHA: {e}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. LOOP DE EXECU√á√ÉO\n",
        "# ==============================================================================\n",
        "# Pega os arquivos parciais\n",
        "arquivos = sorted(glob.glob(os.path.join(INPUT_DIR, \"*.parquet\")))\n",
        "# Filtra para n√£o pegar arquivo final antigo, se houver\n",
        "arquivos = [f for f in arquivos if \"df_completo\" not in f]\n",
        "\n",
        "if not arquivos:\n",
        "    print(\"ERRO: Nenhum arquivo encontrado para processar.\")\n",
        "else:\n",
        "    print(f\"Iniciando processamento de {len(arquivos)} arquivos.\\n\")\n",
        "\n",
        "    for arq in arquivos:\n",
        "        nome_base = os.path.basename(arq)\n",
        "        # Cria nome de sa√≠da: \"dengue_limpo_part_2021.parquet\"\n",
        "        arq_saida = os.path.join(OUTPUT_DIR, f\"dengue_limpo_{nome_base}\")\n",
        "        processar_lote(arq, arq_saida)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"PROCESSO FINALIZADO!\")\n",
        "    print(f\"Todos os arquivos processados est√£o na pasta:\\n{OUTPUT_DIR}\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"COMO USAR AGORA:\")\n",
        "    print(\"N√£o tente ler um arquivo s√≥. Leia a PASTA inteira:\")\n",
        "    print(f\"df = pd.read_parquet('{OUTPUT_DIR}')\")"
      ],
      "metadata": {
        "id": "gbqpxVo8jdea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste se o resultando atende?!"
      ],
      "metadata": {
        "id": "ue1Al9hjuu3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import gc\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURA√á√ÉO\n",
        "# ==============================================================================\n",
        "DATA_DIR = \"/content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet\"\n",
        "PASTA_DOS_DADOS = os.path.join(DATA_DIR, \"Dataset_Pronto_Para_Uso\")\n",
        "\n",
        "print(f\"üìÇ Lendo dados da pasta: {PASTA_DOS_DADOS}...\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CARREGAMENTO ROBUSTO (Bypass do erro PyArrow)\n",
        "# ==============================================================================\n",
        "try:\n",
        "    # Passo 1: Listar os arquivos na pasta manualmente\n",
        "    arquivos_parquet = sorted(glob.glob(os.path.join(PASTA_DOS_DADOS, \"*.parquet\")))\n",
        "\n",
        "    if not arquivos_parquet:\n",
        "        raise FileNotFoundError(\"Nenhum arquivo encontrado na pasta!\")\n",
        "\n",
        "    print(f\"   Encontrados {len(arquivos_parquet)} arquivos. Lendo um a um...\")\n",
        "\n",
        "    lista_dfs = []\n",
        "\n",
        "    # Passo 2: Ler individualmente (Isso evita o erro de Schema Mismatch)\n",
        "    for arquivo in arquivos_parquet:\n",
        "        nome = os.path.basename(arquivo)\n",
        "        print(f\"   -> Carregando: {nome}...\", end=\" \")\n",
        "\n",
        "        # L√™ o arquivo isolado\n",
        "        df_temp = pd.read_parquet(arquivo)\n",
        "        lista_dfs.append(df_temp)\n",
        "        print(\"OK.\")\n",
        "\n",
        "    # Passo 3: O Pandas junta e resolve os conflitos de tipo (Null vs String)\n",
        "    print(\"   -> Consolidando tabelas (Pandas Concat)...\")\n",
        "    df_final = pd.concat(lista_dfs, ignore_index=True)\n",
        "\n",
        "    # Limpa mem√≥ria auxiliar\n",
        "    del lista_dfs\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"‚úÖ SUCESSO! Dataset carregado na mem√≥ria.\")\n",
        "    print(f\"üìä Dimens√µes Finais: {df_final.shape[0]:,} linhas x {df_final.shape[1]} colunas\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå ERRO CR√çTICO: {e}\")\n",
        "    raise\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. VERIFICA√á√ÉO R√ÅPIDA (S√≥ roda se o carregamento funcionar)\n",
        "# ==============================================================================\n",
        "if 'df_final' in locals():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üîç CHECKLIST DE INTEGRIDADE\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # A. Anos presentes\n",
        "    if 'Ano_Notificacao' in df_final.columns:\n",
        "        print(\"\\n1. CASOS POR ANO:\")\n",
        "        print(df_final['Ano_Notificacao'].value_counts().sort_index())\n",
        "\n",
        "    # B. Teste de Idade\n",
        "    if 'Idade_Em_Anos' in df_final.columns:\n",
        "        print(\"\\n2. AMOSTRA DE IDADE REAL:\")\n",
        "        print(df_final['Idade_Em_Anos'].dropna().sample(5))\n",
        "\n",
        "    # C. Teste de Gravidade\n",
        "    if 'Descricao_Classificacao' in df_final.columns:\n",
        "        print(\"\\n3. GRAVIDADE (Amostra):\")\n",
        "        print(df_final['Descricao_Classificacao'].value_counts().head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jr8KY5ikri7U",
        "outputId": "9d87a7d1-6a22-4cb1-f6ac-124978939bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Lendo dados da pasta: /content/drive/MyDrive/Projeto Integrado (2¬∫ Semestre)/Parquet/Dataset_Pronto_Para_Uso...\n",
            "   Encontrados 5 arquivos. Lendo um a um...\n",
            "   -> Carregando: dengue_limpo_part_dengue_2021.parquet... OK.\n",
            "   -> Carregando: dengue_limpo_part_dengue_2022.parquet... OK.\n",
            "   -> Carregando: dengue_limpo_part_dengue_2023.parquet... OK.\n",
            "   -> Carregando: dengue_limpo_part_dengue_2024.parquet... "
          ]
        }
      ]
    }
  ]
}